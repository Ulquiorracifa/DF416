---
typora-root-url: pic
---



### 矫正方法：

极线矫正

：参数估计（备矫正使用）

- [ ] 已知参数估计变换矩阵
- [ ] 8点对估计矩阵



：细化纹理

- [ ] 规约矫正范围
- [ ] 交叠区域单应变换扭曲大
- [ ] 左右目不可定位区域块纹理



### 匹配方法：

1. 能量最小化

   （应用场景[光照环境差异较大]）

   

2. 特征点对匹配

   （增加特征点对[适中场景]）

   osa

   

3. 区域框相似度匹配

   （调整框选区域步长，框距）

   匹配策略

4. 最小生成树代价的聚合（半全局）

   双边滤波引入空间和像素值

5. 

   

   

   

   

### 细匹配:

- [ ] 细致纹理（初步实现）





Store：

rip-map，

osa 采样（原ransac）



idea：

- 双边滤波加入ma映射距离 而非rectify后空间距离

- 精匹配加入分离成（尺度或深度） 

- 树可理解为标准采样间隔的图  （是否可泛化成连续树）

  

- 曲面拟合的亚像素定位算法、基于灰度梯度的亚像素定位算法、基于迭代求解的亚像素定位算法（区域散斑加深曲面拟合度、....)

- 亚像素结合极线矫正权重

- 反射光滑曲面的定位(......)(用于迭代近似(判断问题))

  

  

  

  

  

  ma半径4sigma会取到90%能量





### MC-CNN

2015年

##### 训练自KITTI or Middlebury  数据集，使用其GT图

左右图对：n×n大小，中心左（x,y）；中心右（x-d-Oneg,y）;d为对应正确匹对点的差；

Oneg提供一个范围[dataset_neg_low,dataset_neg_high]或[-dataset_neg_high,dataset_neg_low]

正确点位置为（x-d-Opos,y）



![1561973550062](/1561973550062.png)



Opos从[-dataset pos; dataset pos ]中取，和立体匹配策略有关，dataset pos<=1（等价亚像素匹配）



##### 网络骨架

###### fast 框架：

![1561973550062](/1561973550062.png)

hinge loss:

以以相同图像位置为中心的成对图像对为示例，即存在正负样本对

max(0; m + s- - s+) ,S+为正样本，S-为负样本，仅当正样本比负样本高m ，才存在正值，（m set 0.2）

其他超参数（子网络卷积层数量、核尺寸、每层特征图数、输入尺寸）



###### accurate 框架：（改为0,1分类）

![fast-mc-cnn](/1561975324014.png)

代替了叉乘相似度的匹配，改成了多个全连接层（删去了归一化）

二值交叉熵 loss：二分类，t = 1为匹配对，0为匹配错

t log(s) + (1 - t) log(1 - s) 

实验证明该loss更准确（叉乘不适用交叉熵）

额外超参（全连接层数量、每个全连接单元数）



匹配代价：

![1561989721100](/1561989721100.png)

网络优点：

1.图像每个位置仅计算一轮图像

2.sub-networks整图计算（不使用小区域框独立匹配）（个人理解）

3.全连接层中可单次前向传播输出，（替换每个fc为1*1全卷积网络）；仍需考虑双目视差d（KITTI max为228，Middlebury max为400）,全连接层（后匹配模块）须迭代d次



### 立体匹配算法：



comprises cross-based cost aggregation, semiglobal matching, a left-right
consistency check, subpixel enhancement, a median, and a bilateral filter 

待定

