---
typora-copy-images-to: pic
typora-root-url: pic
---

### 2019cvpr汇总：



1. ##### Anchor-Free

   paper:<https://arxiv.org/pdf/1903.00621v1.pdf>

   对小物体检测常用FPN（Feature Pyramid Network）在不同尺度上检测物体。fpn融合深层和浅层的特征。

   如faster RCNN中的ROI pooling用于分拣特征，Mask RCNN中庸的ROIAlign.

   

   将size不作为分类那些feature map参与检测的参数。

   （60x60大小的car和50x50大小的car被分在了不同feature map，50x50和40x40的被分在了同一级feature map，无法判断优劣）

   

   ###### 文章提出：

   **Feature Selective Anchor-Free Module (FSAF)**

   ![img](https://github.com/Ulquiorracifa/DF416/blob/master/pic/gYUsOT36vfoqaonDicB29VlmiczTGRQltU7x.png?raw=true)

   

   **Ground-truth和loss的设计**

   ![img](https://github.com/Ulquiorracifa/DF416/blob/master/pic/gYUsOT36vfoqaonDicB29VlmiczT.png?raw=true)

   分支对应的gt是图中白色区域内值为1，表示正样本，黑色区域内值为0，表示负样本，灰色区域是忽略区域不回传梯度。

   :<u>不怎么理解</u>，在文中都是自己定义的大小，

   

   FSAF的设计就是为了达到自动选择最佳Feature的目的，最佳Feature是由各个feature level共同决定。

   ![img](https://github.com/Ulquiorracifa/DF416/blob/master/pic/gYUsOT36vfoqaonDicC.png?raw=true)

   

   paper:https://arxiv.org/pdf/1904.01355.pdf

   ##### FCOS

   

   

   

   

   

   ​					

2. Pyramid Mask Text Detector（只完善样本标签区分等操作）

   利用maskR-CNN的分割方法定位文本：

   problem：

   1. 过简单的监督（和物体分割不同 ，文本往往是四边形框选区域）
   2. 标签不准确（大部分背景区域，属样本噪声）
   3. 错误传递（用bbox作为语义分割，对于并未全覆盖的例子是脆弱的（bbox倾向于排除外部内容））

   #### **baseline**：

   ##### 数据增强：

   1.50%概率水平翻转图片

   2.随机resize长宽到640-2560之间

   3.从第二步中随机裁剪640*640区域

   ##### RPN anchor：

   在FPN模块中，量化基本的anchor大小、anchor搜索的特征图、anchor的长宽比。

   文章采用了（1/4,1/8,1/16,1/32）四个尺度特征图进行搜索4*4的大小的anchor，长宽比为（0.17; 0.44; 1.13; 2.90; 7.46 ）[确定长宽比由分布{0.17+-:5%，7.46+-:95%}得到]

   ##### OHEM:

   使用OHEM检索评估得出难样本，用以更新网络

   #### PTMD： 

   ​		points：

   1.通常文本为四边形，这样破坏了形状信息

   2.文本框形式转像素不准确（前后景在maskrcnn中较为重要，因为内容落实到像素，会影响loss）<u>***（标签周围做卷积？滤波前后景预测概率图；结果去卷积得区域？）***</u>

   3.bbox的定位错误会影响框内物体分割的结果。

   ##### score定义方法：

   ![1559979657809](https://raw.githubusercontent.com/Ulquiorracifa/DF416/master/pic/1559979657809.png)

   O为区域高斯金字塔中心：

   xo = （xA+xB+xC+xD）/4

   yo = （yA+yB+yC+yD）/4

   P为区域内一点，可有OM,ON组合得到（M,N为A,B,C,D中取得的两点）

   ![1559979981667](https://raw.githubusercontent.com/Ulquiorracifa/DF416/master/pic/1559979981667.png)

   αβ可计算得：

   ![1559980070115](https://raw.githubusercontent.com/Ulquiorracifa/DF416/master/pic/1559980070115.png)

   则定义的scoreP为

   ![1559980111352](https://raw.githubusercontent.com/Ulquiorracifa/DF416/master/pic/1559980111352.png)

   ##### 网络的loss：

   和maskRCNN类似，定义为

   ![1559980279190](https://raw.githubusercontent.com/Ulquiorracifa/DF416/master/pic/1559980279190.png)

   ##### 由预测值推断结果文本框：

   预测的值大于0.1的点为positive点，找中心点，定义为金字塔中心点，赋为1，同时获得金字塔的4个侧平面（Ax+By+Cz+D=0,C =1）。

   对预测出的点分配给这四个平面，再返回上一步的计算中心点，采用最小二乘法更新4个平面。

   ↑上述操作直至最小二乘值小于一定阈值（文章设为1e-4）或者到达最大迭代次数（文章：10）

   ![1559983533703](https://raw.githubusercontent.com/Ulquiorracifa/DF416/master/pic/1559983533703.png)

   

3. 

##### 